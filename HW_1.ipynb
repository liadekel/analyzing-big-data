{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "HW 1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liadekel/analyzing-big-data/blob/master/HW_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fq8BHLiYCyE",
        "colab_type": "text"
      },
      "source": [
        "# Homework Assignment 1\n",
        "### [The Art of Analyzing Big Data - The Data Scientist’s Toolbox](https://www.ise.bgu.ac.il/labs/fire/lectures.html)\n",
        "#### By Dr. Michael Fire "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYvqtKSOYCyG",
        "colab_type": "text"
      },
      "source": [
        "For this homework you will need to write code that analyzes real-world datasets. The code needs to be written in Python using the [sqlite3](https://docs.python.org/2/library/sqlite3.html) package. \n",
        "\n",
        "**Please note:** You need to answer only the questions that match your ID first digit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AML-gkV-YCyI",
        "colab_type": "text"
      },
      "source": [
        "# 1. Babies Names Dataset (35pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvkBrt7SYCyK",
        "colab_type": "text"
      },
      "source": [
        "**Task 1 (for everyone):** Write a code that uses the  [**babies names dataset**](https://catalog.data.gov/dataset/baby-names-from-social-security-card-applications-data-by-state-and-district-of-#topic=developers_navigation) and creates a table named (Names) with the dataset data and the following columns: 'State', 'Gender', 'Name', 'Number', and 'Year' (5pt)\n",
        "**Bonus:** Load the data using a Batch INSERT SQL Query (2pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9nEyTepERV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# restart state\n",
        "! rm -rf ./datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VdoedCI8H2KB",
        "outputId": "ec00558e-fb60-411f-9e2d-6628eb24583a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Creating a dataset directory\n",
        "!mkdir ./datasets\n",
        "!mkdir ./datasets/us-baby-name\n",
        "# download the dataset using wget\n",
        "!wget --directory-prefix ./datasets/us-baby-name https://www.ssa.gov/oact/babynames/state/namesbystate.zip\n",
        "!unzip ./datasets/us-baby-name/*.zip  -d ./datasets/us-baby-name/namesbystate\n",
        "# concatenate to one file\n",
        "!cat ./datasets/us-baby-name/namesbystate/*.TXT >> ./datasets/us-baby-name/namesbystate.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./datasets’: File exists\n",
            "--2020-03-25 10:05:39--  https://www.ssa.gov/oact/babynames/state/namesbystate.zip\n",
            "Resolving www.ssa.gov (www.ssa.gov)... 137.200.4.16, 2001:1930:d07::aaaa\n",
            "Connecting to www.ssa.gov (www.ssa.gov)|137.200.4.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21974087 (21M) [application/zip]\n",
            "Saving to: ‘./datasets/us-baby-name/namesbystate.zip’\n",
            "\n",
            "namesbystate.zip    100%[===================>]  20.96M   335KB/s    in 68s     \n",
            "\n",
            "2020-03-25 10:06:48 (318 KB/s) - ‘./datasets/us-baby-name/namesbystate.zip’ saved [21974087/21974087]\n",
            "\n",
            "Archive:  ./datasets/us-baby-name/namesbystate.zip\n",
            "  inflating: ./datasets/us-baby-name/namesbystate/AK.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/AL.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/AR.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/AZ.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/CA.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/CO.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/CT.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/DC.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/DE.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/FL.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/GA.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/HI.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/IA.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/ID.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/IL.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/IN.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/KS.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/KY.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/LA.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/MA.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/MD.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/ME.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/MI.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/MN.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/MO.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/MS.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/MT.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/NC.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/ND.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/NE.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/NH.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/NJ.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/NM.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/NV.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/NY.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/OH.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/OK.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/OR.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/PA.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/RI.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/SC.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/SD.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/StateReadMe.pdf  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/TN.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/TX.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/UT.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/VA.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/VT.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/WA.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/WI.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/WV.TXT  \n",
            "  inflating: ./datasets/us-baby-name/namesbystate/WY.TXT  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHULZ_GjBBYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sqlite3\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "%matplotlib inline\n",
        "TEXT_PATH = './datasets/us-baby-name/namesbystate.txt'\n",
        "DB_PATH = './datasets/us-baby-name/namebystate.sqlite'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZv3Vlj5BXWy",
        "colab_type": "code",
        "outputId": "c5eb0ab8-a420-46e6-eb5e-8ab9cfd0933f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "conn = sqlite3.connect(DB_PATH) # connecting to the database\n",
        "c = conn.cursor() # creating a cursor object\n",
        "# create Names table\n",
        "c.execute(\n",
        "        '''CREATE TABLE IF NOT EXISTS Names\n",
        "             ([State] text,\n",
        "              [Gender] text,\n",
        "              [Year] integer,\n",
        "              [Name] text,\n",
        "              [Number] integer)\n",
        "        '''\n",
        ")\n",
        "\n",
        "#load data into convinient format\n",
        "with open(TEXT_PATH) as f:\n",
        "    names = f.readlines()\n",
        "names = [tuple(name.strip().split(\",\")) for name in names]\n",
        "\n",
        "# insert data to db\n",
        "c.executemany(\n",
        "    '''INSERT INTO Names(State, Gender, Year, Name, Number)\n",
        "       values (?,?,?,?,?)\n",
        "    ''', names\n",
        ")\n",
        "# show all rows in Names\n",
        "#c.execute(\"SELECT * FROM Names\").fetchall()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sqlite3.Cursor at 0x7f87c8c20d50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEbvkQhCYCyP",
        "colab_type": "text"
      },
      "source": [
        "**Task 2 (for everyone):** Write a query that returns the statistics for the name William (5pt). Use the [the timeit package](https://docs.python.org/3/library/timeit.html) to measure the time it takes the query to run (5pt). **Bonus:** [Create an index](https://www.w3schools.com/sql/sql_create_index.asp)  on the _Name_ column and use the [the timeit package](https://docs.python.org/3/library/timeit.html) to measure the time it takes the query to run with the index (5pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBCHPAOzYCyR",
        "colab_type": "code",
        "outputId": "f754dbae-e5f7-4a45-9c69-8a8c0ae9346e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "import time\n",
        "import timeit\n",
        "\n",
        "def test():\n",
        "    query = \"SELECT COUNT(*) FROM Names WHERE Name='William'\"\n",
        "    print(\"There are {} williams\".format(c.execute(query).fetchone()[0]))\n",
        "\n",
        "c.execute(\"DROP INDEX IF EXISTS idx_name\")\n",
        "print(\"Time without index:{}\".format(timeit.timeit(\"test()\", globals=globals(), number=1)))\n",
        "\n",
        "c.execute('''CREATE INDEX IF NOT EXISTS idx_name\n",
        "             ON Names (name);''')\n",
        "print(\"Time with index:{}\".format(timeit.timeit(\"test()\", globals=globals(), number=1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 6726 williams\n",
            "Time without index:0.44438184000000547\n",
            "There are 6726 williams\n",
            "Time with index:0.0006709849999424478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dClZxXjYCyU",
        "colab_type": "text"
      },
      "source": [
        "### <span style=\"color:red\"> Please answer only **one** of the following questions according to your ID number (use the formula **<YOUR_ID> mod 4 +1**) </span>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDpqwgwQYCyV",
        "colab_type": "code",
        "outputId": "878f6e9e-fe0e-4554-c257-0094289f9aa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# which question to answer - put your ID number and run the code \n",
        "your_id  = \"316460443\"\n",
        "q = int(your_id) % 4 + 1\n",
        "print(\"You need to answer question number %s\" % q)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You need to answer question number 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGU71KQ8YCyZ",
        "colab_type": "text"
      },
      "source": [
        "***Question 1:*** Write a function that returns how many babies were born in a given state in a given year.\n",
        "Use it to calculate the number of babies born in LA in 1950 (10pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RB3GjaaYCya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "510Wry5WYCye",
        "colab_type": "text"
      },
      "source": [
        "***Question 2:*** Write a function that returns how many male babies were born between a given range of years.\n",
        "Use it to calculate how many babies were born between 1970 and 1975  (10pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5wOKWsBYCyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x721dD1NYCyi",
        "colab_type": "text"
      },
      "source": [
        "**Question 3:** Write a function that returns the most common female name in a given state. Use it to calculate the most common female name in Wasington in 1987 (10pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3t_ouDoYCyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRyUoBvhYCyl",
        "colab_type": "text"
      },
      "source": [
        "**Question 4:** Write a function that returns how many male babies named _William_ where born in a given state in a given year. Use it to find the state in which the highest number of babies _William_ where born in 1999 (10pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz1q1mvPYCym",
        "colab_type": "code",
        "outputId": "763f9f58-4e84-466d-8a32-e2fea5c1cba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def find_babies(year, state=None, gender='M', name='William'):\n",
        "    num = c.execute(\n",
        "    f'''SELECT COUNT(*)\n",
        "        FROM Names\n",
        "        WHERE State='{state}' AND\n",
        "              Gender='{gender}'AND\n",
        "              Name='{name}' AND\n",
        "              Year={year}\n",
        "    '''\n",
        "    ).fetchone()[0]\n",
        "    print(f'Number of babies with name={name}, year={year}, gender={gender} is {num} in state={state}')\n",
        "\n",
        "def find_babies_max(year, state=None, gender='M', name='William'):\n",
        "    num, state = c.execute(\n",
        "    f'''SELECT COUNT(*), State\n",
        "        FROM Names\n",
        "        WHERE Gender='{gender}'AND\n",
        "              Name='{name}' AND\n",
        "              Year={year}\n",
        "        ORDER BY 1 DESC\n",
        "    '''\n",
        "    ).fetchone()\n",
        "    print(f'Max number of babies with name={name}, year={year}, gender={gender} is {num} in state={state}')\n",
        "\n",
        "\n",
        "find_babies(year='1999', state='AK')\n",
        "# implemented more efficiently using single query\n",
        "# could also be implemented with for loop\n",
        "find_babies_max(year=1999)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of babies with name=William, year=1999, gender=M is 1 in state=AK\n",
            "Max number of babies with name=William, year=1999, gender=M is 51 in state=WY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THz0vDHHYCyo",
        "colab_type": "text"
      },
      "source": [
        "**Question (for everyone):** For the state of NY write code that calculates the second most popular female/male names in each decade (10pt). **Bonus**: Visualize it somehow using Matplotlib (5pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVRTQGOS_3G9",
        "colab_type": "code",
        "outputId": "156abbd5-6212-4a91-8595-0fb56e2bfea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def find_popular_in_decade(decade, gender, state='NY'):\n",
        "    print(c.execute(\n",
        "    f'''SELECT SUBSTR(Year, 1, 3) || '0', Gender, Name, COUNT(*)\n",
        "        FROM Names\n",
        "        WHERE State='{state}' AND\n",
        "              Gender='{gender}' AND\n",
        "              (SUBSTR(Year, 1, 3) || '0')='{decade}'\n",
        "        GROUP BY SUBSTR(Year, 1, 3), Name\n",
        "        ORDER BY 4 DESC LIMIT 2\n",
        "    '''\n",
        "    ).fetchall()[1]) # second on descending order\n",
        "\n",
        "\n",
        "for decade in range(1910, 2010, 10):\n",
        "    find_popular_in_decade(decade=decade, gender='M')\n",
        "    find_popular_in_decade(decade=decade, gender='F')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('1910', 'M', 'Abe', 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmdQrLL9YCyp",
        "colab_type": "text"
      },
      "source": [
        "# 2. Flavors of Cacao Dataset (15pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTpNKH7UYCyq",
        "colab_type": "text"
      },
      "source": [
        "Using the [Flavors of Cacao](https://www.kaggle.com/rombikuboktaeder/choco-flavors) dataset, answer the following questions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbg9gkVtYCyr",
        "colab_type": "text"
      },
      "source": [
        "**Question 1:** Write a function that returns the number of bars manufactured where the bars' BroadBean Origin is a given country. Use the function to calculate the number of bars where BroadBean Origin is 'Fiji' (15pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5FWfEiaYCys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GCvKxWtYCyu",
        "colab_type": "text"
      },
      "source": [
        "**Question 2:** Write a function that returns the maximal and average cocoa percentage in a bar manufactured by a company in a specific country. Use the function to calculate the maximal and average cocoa percentage in bars manufactured by a Swiss company (15pt)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZJXxtwWYCyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlYqUA1xYCyx",
        "colab_type": "text"
      },
      "source": [
        "**Question 3:** Calculate the second most common bean type(s) and the most rare bean type(s) (15\n",
        "pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk0qIAiwYCyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOg-NK_lYCyz",
        "colab_type": "text"
      },
      "source": [
        "**Question 4:** Calculate the number of reviews and the average rating in each year. Calculate the number of reviews and the average rating of each company in each year (15pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8qwHAldYCy0",
        "colab_type": "code",
        "outputId": "ab3d38e4-b7cf-4d30-818b-44d3ab08947b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!mkdir /root/.kaggle/\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Installing the Kaggle package\n",
        "!pip install kaggle \n",
        "\n",
        "#Important Note: complete this with your own key - after running this for the first time remmember to **remove** your API_KEY\n",
        "api_token = {\"username\":\"liaddekel\",\"key\":\"f108a5e28c6e44704d469f7ae7614d16\"}\n",
        "\n",
        "\n",
        "# creating kaggle.json file with the personal API-Key details \n",
        "# You can also put this file on your Google Drive\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "  json.dump(api_token, file)\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle/’: File exists\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.11.28)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.38.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLQlzfKb-eI0",
        "colab_type": "code",
        "outputId": "be61dc79-0b50-494b-9b5e-4e2dd78b845b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# download and unzip dataset\n",
        "!kaggle datasets list -s choco_flavors\n",
        "!kaggle datasets download rombikuboktaeder/choco-flavors -p ./datasets/choco-flavors/\n",
        "!unzip ./datasets/choco-flavors/choco-flavors.zip -d ./datasets/choco-flavors/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                             title          size  lastUpdated          downloadCount  \n",
            "------------------------------  -------------  ----  -------------------  -------------  \n",
            "rombikuboktaeder/choco-flavors  choco_flavors  30KB  2018-04-01 04:36:29            522  \n",
            "Downloading choco-flavors.zip to ./datasets/choco-flavors\n",
            "  0% 0.00/30.3k [00:00<?, ?B/s]\n",
            "100% 30.3k/30.3k [00:00<00:00, 26.2MB/s]\n",
            "Archive:  ./datasets/choco-flavors/choco-flavors.zip\n",
            "  inflating: ./datasets/choco-flavors/flavors_of_cacao.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PejP_U2WcNuW",
        "colab_type": "code",
        "outputId": "8a33f9e5-298b-4313-ec55-40b9b1bc0362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!pip install pony"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pony\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/e4/45fa6185e86edfa97eef5a4fbe3f29f537de7f36c032ff7c54676310dcb1/pony-0.7.13.tar.gz (284kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 3.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30kB 5.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 61kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 71kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 81kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 92kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 102kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 112kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 122kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 143kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 153kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 163kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 174kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 184kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 194kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 204kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 215kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 225kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 235kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 245kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 256kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 266kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 276kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286kB 5.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pony\n",
            "  Building wheel for pony (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pony: filename=pony-0.7.13-cp36-none-any.whl size=345363 sha256=fd97cfb439d325026575e041799e2358c3f2948b949e442d6a82f61e0254be51\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/c7/66/a9192d0ea4bcb17a25164284ec89b4563a6afbf7333947c0ea\n",
            "Successfully built pony\n",
            "Installing collected packages: pony\n",
            "Successfully installed pony-0.7.13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoU_K5WAAiFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pony.orm import *\n",
        "# Creating a new database\n",
        "db = Database()\n",
        "db.bind(provider='sqlite', filename='/content/datasets/choco-flavors/choco-flavors.pony.db', create_db=True)\n",
        "\n",
        "class ChocoFlavor(db.Entity):\n",
        "    Company = Optional(str)\n",
        "    BeanOrigin = Required(str)\n",
        "    REF = Required(int)\n",
        "    ReviewDate = Required(int)\n",
        "    CocoaPrecent = Required(str)\n",
        "    Location = Required(str)\n",
        "    Rating = Required(float)\n",
        "    BeanType = Optional(str)\n",
        "    BroadBeanOrigin = Optional(str)\n",
        "     \n",
        "#set_sql_debug(True) # helps to see what SQL commands are running\n",
        "db.generate_mapping(create_tables=True) # create tables"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phiLl7erhMOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! rm -rf '/content/datasets/choco-flavors/choco-flavors.pony.db'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IgD6Chibz8Q",
        "colab_type": "code",
        "outputId": "9aa8bdef-1fca-4773-d6a1-b486feb8c419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "\n",
        "# pandas can find csv inside the zip itself\n",
        "df = pandas.read_csv(\"./datasets/choco-flavors/choco-flavors.zip\")\n",
        "df = df.replace(np.nan, '', regex=True)\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    ChocoFlavor(\n",
        "            Company=row['Company\\xa0\\n(Maker-if known)'],\n",
        "            BeanOrigin=row['Specific Bean Origin\\nor Bar Name'],\n",
        "            REF=row['REF'],\n",
        "            ReviewDate=row['Review\\nDate'],\n",
        "            CocoaPrecent=row['Cocoa\\nPercent'],\n",
        "            Location=row['Company\\nLocation'],\n",
        "            Rating=row['Rating'],\n",
        "            BeanType=row['Bean\\nType'],\n",
        "            BroadBeanOrigin=row['Broad Bean\\nOrigin']\n",
        "    )\n",
        "show(ChocoFlavor)\n",
        "commit()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class ChocoFlavor(Entity):\n",
            "    id = PrimaryKey(int, auto=True)\n",
            "    Company = Optional(str, default='')\n",
            "    BeanOrigin = Required(str)\n",
            "    REF = Required(int)\n",
            "    ReviewDate = Required(int)\n",
            "    CocoaPrecent = Required(str)\n",
            "    Location = Required(str)\n",
            "    Rating = Required(float)\n",
            "    BeanType = Optional(str, default='')\n",
            "    BroadBeanOrigin = Optional(str, default='')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbhpmyMjk1U8",
        "colab_type": "code",
        "outputId": "c2e6e3f0-2e25-4f3c-aacd-7650b131e4c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# number of reviews and average rating per year\n",
        "\"\"\"\n",
        "    SELECT \"c\".\"ReviewDate\", COUNT(DISTINCT \"c\".\"id\"), AVG(\"c\".\"Rating\")\n",
        "    FROM \"ChocoFlavor\" \"c\"\n",
        "    GROUP BY \"c\".\"ReviewDate\n",
        "\"\"\"\n",
        "list(select((c.ReviewDate, count(c), avg(c.Rating)) for c in ChocoFlavor))\n",
        "\n",
        "# number of reviews and average rating per company per year\n",
        "\"\"\"\n",
        "    SELECT \"c\".\"Company\", COUNT(DISTINCT \"c\".\"id\"), AVG(\"c\".\"Rating\")\n",
        "    FROM \"ChocoFlavor\" \"c\"\n",
        "    GROUP BY \"c\".\"Company\"\n",
        "\"\"\"\n",
        "list(select((c.Company, c.ReviewDate, count(c), avg(c.Rating)) for c in ChocoFlavor))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SELECT \"c\".\"ReviewDate\", COUNT(DISTINCT \"c\".\"id\"), AVG(\"c\".\"Rating\")\n",
            "FROM \"ChocoFlavor\" \"c\"\n",
            "GROUP BY \"c\".\"ReviewDate\"\n",
            "\n",
            "SELECT \"c\".\"Company\", \"c\".\"ReviewDate\", COUNT(DISTINCT \"c\".\"id\"), AVG(\"c\".\"Rating\")\n",
            "FROM \"ChocoFlavor\" \"c\"\n",
            "GROUP BY \"c\".\"Company\", \"c\".\"ReviewDate\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('A. Morin', 2012, 2, 3.625),\n",
              " ('A. Morin', 2013, 11, 3.3181818181818183),\n",
              " ('A. Morin', 2014, 5, 3.5),\n",
              " ('A. Morin', 2015, 4, 3.1875),\n",
              " ('A. Morin', 2016, 1, 3.75),\n",
              " ('AMMA', 2010, 4, 3.5625),\n",
              " ('AMMA', 2013, 1, 3.25),\n",
              " ('Acalli', 2015, 2, 3.75),\n",
              " ('Adi', 2011, 4, 3.25),\n",
              " ('Aequare (Gianduja)', 2009, 2, 2.875),\n",
              " ('Ah Cacao', 2009, 1, 3.0),\n",
              " (\"Akesson's (Pralus)\", 2010, 2, 2.75),\n",
              " (\"Akesson's (Pralus)\", 2011, 1, 3.75),\n",
              " ('Alain Ducasse', 2013, 2, 2.5),\n",
              " ('Alain Ducasse', 2014, 3, 2.8333333333333335),\n",
              " ('Alexandre', 2017, 4, 3.5),\n",
              " ('Altus aka Cao Artisan', 2013, 5, 3.0),\n",
              " ('Altus aka Cao Artisan', 2016, 5, 2.7),\n",
              " ('Amano', 2007, 3, 3.4166666666666665),\n",
              " ('Amano', 2008, 1, 2.75),\n",
              " ('Amano', 2009, 1, 3.0),\n",
              " ('Amano', 2010, 3, 3.5833333333333335),\n",
              " ('Amano', 2011, 1, 4.0),\n",
              " ('Amatller (Simon Coll)', 2009, 4, 2.875),\n",
              " ('Amazona', 2013, 2, 3.375),\n",
              " ('Ambrosia', 2015, 6, 3.25),\n",
              " ('Amedei', 2006, 2, 4.5),\n",
              " ('Amedei', 2007, 10, 3.725),\n",
              " ('Amedei', 2012, 1, 3.75),\n",
              " ('Anahata', 2014, 1, 3.0),\n",
              " ('Animas', 2016, 1, 3.5),\n",
              " ('Ara', 2014, 4, 2.8125),\n",
              " ('Arete', 2015, 9, 3.5),\n",
              " ('Arete', 2016, 13, 3.5576923076923075),\n",
              " ('Artisan du Chocolat', 2008, 1, 3.75),\n",
              " ('Artisan du Chocolat', 2009, 6, 2.7083333333333335),\n",
              " ('Artisan du Chocolat', 2010, 5, 3.1),\n",
              " ('Artisan du Chocolat', 2011, 2, 3.375),\n",
              " ('Artisan du Chocolat', 2012, 1, 3.75),\n",
              " ('Artisan du Chocolat', 2013, 1, 3.25),\n",
              " ('Artisan du Chocolat (Casa Luker)', 2013, 1, 2.75),\n",
              " ('Askinosie', 2007, 2, 2.75),\n",
              " ('Askinosie', 2009, 1, 3.75),\n",
              " ('Askinosie', 2011, 2, 3.75),\n",
              " ('Askinosie', 2016, 1, 3.75),\n",
              " ('Bahen & Co.', 2012, 3, 2.6666666666666665),\n",
              " ('Bahen & Co.', 2015, 2, 3.375),\n",
              " ('Bakau', 2015, 2, 3.125),\n",
              " ('Bar Au Chocolat', 2012, 3, 3.5),\n",
              " ('Bar Au Chocolat', 2014, 1, 4.0),\n",
              " ('Bar Au Chocolat', 2015, 1, 3.5),\n",
              " (\"Baravelli's\", 2012, 1, 2.75),\n",
              " ('Batch', 2016, 3, 3.5),\n",
              " ('Beau Cacao', 2017, 2, 3.125),\n",
              " ('Beehive', 2016, 4, 2.75),\n",
              " ('Belcolade', 2010, 4, 2.9375),\n",
              " ('Bellflower', 2016, 3, 3.4166666666666665),\n",
              " ('Belyzium', 2016, 3, 3.0833333333333335),\n",
              " ('Benoit Nihant', 2011, 2, 3.875),\n",
              " ('Benoit Nihant', 2013, 4, 3.625),\n",
              " ('Bernachon', 2012, 1, 2.75),\n",
              " ('Beschle (Felchlin)', 2010, 4, 3.375),\n",
              " ('Beschle (Felchlin)', 2011, 4, 3.375),\n",
              " ('Bisou', 2015, 4, 2.6875),\n",
              " ('Bittersweet Origins', 2008, 4, 3.3125),\n",
              " ('Bittersweet Origins', 2009, 4, 3.3125),\n",
              " ('Bittersweet Origins', 2010, 5, 3.15),\n",
              " ('Bittersweet Origins', 2012, 1, 3.5),\n",
              " ('Black Mountain', 2008, 3, 2.8333333333333335),\n",
              " ('Black River (A. Morin)', 2014, 1, 2.75),\n",
              " ('Blanxart', 2009, 1, 2.75),\n",
              " ('Blanxart', 2013, 1, 3.5),\n",
              " ('Blue Bandana', 2012, 2, 3.625),\n",
              " ('Blue Bandana', 2016, 4, 3.1875),\n",
              " ('Bonnat', 2006, 7, 3.4642857142857144),\n",
              " ('Bonnat', 2007, 1, 2.5),\n",
              " ('Bonnat', 2008, 1, 4.0),\n",
              " ('Bonnat', 2009, 4, 2.9375),\n",
              " ('Bonnat', 2011, 8, 3.625),\n",
              " ('Bonnat', 2013, 2, 3.375),\n",
              " ('Bonnat', 2014, 3, 3.6666666666666665),\n",
              " ('Bonnat', 2016, 1, 3.5),\n",
              " ('Bouga Cacao (Tulicorp)', 2009, 2, 2.375),\n",
              " ('Bowler Man', 2014, 2, 2.75),\n",
              " (\"Brasstown aka It's Chocolate\", 2013, 4, 3.3125),\n",
              " (\"Brasstown aka It's Chocolate\", 2014, 2, 3.875),\n",
              " (\"Brasstown aka It's Chocolate\", 2015, 1, 3.75),\n",
              " (\"Brasstown aka It's Chocolate\", 2016, 2, 3.625),\n",
              " ('Brazen', 2015, 6, 3.1666666666666665),\n",
              " ('Breeze Mill', 2013, 1, 3.0),\n",
              " ('Bright', 2014, 4, 3.1875),\n",
              " ('Britarev', 2015, 1, 3.25),\n",
              " ('Bronx Grrl Chocolate', 2013, 1, 2.75),\n",
              " ('Burnt Fork Bend', 2014, 5, 3.15),\n",
              " ('C-Amaro', 2011, 2, 2.375),\n",
              " ('C-Amaro', 2012, 1, 3.0),\n",
              " ('C-Amaro', 2013, 1, 3.5),\n",
              " ('C-Amaro', 2014, 3, 3.0),\n",
              " ('Cacao Arabuco', 2015, 1, 2.5),\n",
              " ('Cacao Atlanta', 2010, 3, 2.5),\n",
              " ('Cacao Atlanta', 2014, 1, 2.5),\n",
              " ('Cacao Barry', 2007, 2, 2.5),\n",
              " ('Cacao Barry', 2008, 1, 2.0),\n",
              " ('Cacao Barry', 2010, 1, 3.0),\n",
              " ('Cacao Barry', 2016, 1, 3.5),\n",
              " ('Cacao Hunters', 2014, 4, 3.25),\n",
              " ('Cacao Hunters', 2015, 1, 3.75),\n",
              " ('Cacao Hunters', 2016, 2, 3.75),\n",
              " ('Cacao Market', 2016, 1, 3.5),\n",
              " ('Cacao Prieto', 2011, 3, 3.3333333333333335),\n",
              " ('Cacao Prieto', 2012, 1, 3.75),\n",
              " ('Cacao Sampaka', 2009, 2, 4.0),\n",
              " ('Cacao Sampaka', 2010, 6, 3.5833333333333335),\n",
              " ('Cacao Sampaka', 2016, 1, 3.5),\n",
              " ('Cacao Store', 2015, 3, 3.25),\n",
              " ('Cacao de Origen', 2014, 4, 3.25),\n",
              " ('Cacao de Origen', 2015, 2, 3.375),\n",
              " ('Cacao de Origin', 2015, 1, 3.25),\n",
              " ('Cacaosuyo (Theobroma Inversiones)', 2013, 1, 3.25),\n",
              " ('Cacaoyere (Ecuatoriana)', 2008, 4, 2.75),\n",
              " ('Callebaut', 2007, 1, 1.0),\n",
              " ('Callebaut', 2008, 1, 2.75),\n",
              " ('Cao', 2016, 5, 2.9),\n",
              " ('Caoni (Tulicorp)', 2008, 6, 2.8333333333333335),\n",
              " ('Captain Pembleton', 2014, 2, 3.625),\n",
              " ('Caribeans', 2012, 2, 2.875),\n",
              " ('Caribeans', 2015, 3, 3.4166666666666665),\n",
              " ('Carlotta Chocolat', 2016, 5, 3.3),\n",
              " ('Castronovo', 2013, 7, 3.0357142857142856),\n",
              " ('Castronovo', 2014, 3, 3.25),\n",
              " ('Castronovo', 2015, 3, 3.5833333333333335),\n",
              " ('Castronovo', 2016, 1, 4.0),\n",
              " ('Cello', 2014, 4, 2.75),\n",
              " ('Cemoi', 2009, 1, 2.75),\n",
              " ('Chaleur B', 2014, 1, 2.75),\n",
              " ('Charm School', 2016, 1, 3.25),\n",
              " ('Chchukululu (Tulicorp)', 2008, 1, 3.0),\n",
              " ('Chchukululu (Tulicorp)', 2010, 1, 2.75),\n",
              " ('Chequessett', 2014, 1, 3.5),\n",
              " ('Chloe Chocolat', 2011, 1, 3.5),\n",
              " ('Chocablog', 2015, 1, 3.25),\n",
              " ('Choco Del Sol', 2014, 2, 3.125),\n",
              " ('Choco Dong', 2015, 2, 3.125),\n",
              " ('ChocoReko', 2015, 1, 3.0),\n",
              " (\"Chocola'te\", 2011, 2, 3.75),\n",
              " ('Chocolarder', 2015, 3, 2.5833333333333335),\n",
              " ('Chocolate Alchemist-Philly', 2016, 2, 2.5),\n",
              " ('Chocolate Con Amor', 2016, 7, 2.892857142857143),\n",
              " ('Chocolate Conspiracy', 2014, 1, 2.75),\n",
              " ('Chocolate Makers', 2015, 3, 3.5),\n",
              " ('Chocolate Tree, The', 2012, 3, 2.8333333333333335),\n",
              " ('Chocolate Tree, The', 2013, 1, 3.75),\n",
              " ('Chocolate Tree, The', 2015, 2, 3.75),\n",
              " ('Chocolats Privilege', 2014, 1, 2.5),\n",
              " ('Chocosol', 2011, 1, 3.25),\n",
              " ('Chocovic', 2007, 3, 2.6666666666666665),\n",
              " ('Chocovic', 2008, 1, 3.5),\n",
              " ('Chocovic', 2009, 2, 3.25),\n",
              " ('Chocovic', 2010, 2, 3.375),\n",
              " ('Chocovivo', 2015, 2, 2.5),\n",
              " ('Choklat', 2009, 5, 2.85),\n",
              " ('Chokolat Elot (Girard)', 2013, 1, 2.75),\n",
              " ('Choocsol', 2016, 1, 3.25),\n",
              " ('Christopher Morel (Felchlin)', 2011, 1, 3.75),\n",
              " ('Chuao Chocolatier', 2009, 1, 3.0),\n",
              " ('Chuao Chocolatier (Pralus)', 2010, 1, 2.75),\n",
              " ('Claudio Corallo', 2008, 3, 2.6666666666666665),\n",
              " ('Claudio Corallo', 2010, 1, 3.75),\n",
              " ('Cloudforest', 2015, 1, 3.5),\n",
              " ('Coleman & Davis', 2015, 1, 3.0),\n",
              " ('Compania de Chocolate (Salgado)', 2008, 4, 3.125),\n",
              " ('Compania de Chocolate (Salgado)', 2010, 1, 3.25),\n",
              " ('Condor', 2015, 1, 3.5),\n",
              " ('Confluence', 2016, 1, 2.75),\n",
              " ('Coppeneur', 2007, 1, 3.0),\n",
              " ('Coppeneur', 2008, 2, 3.0),\n",
              " ('Coppeneur', 2009, 4, 3.375),\n",
              " ('Coppeneur', 2010, 6, 3.0416666666666665),\n",
              " ('Coppeneur', 2012, 4, 3.0625),\n",
              " ('Coppeneur', 2013, 1, 3.25),\n",
              " (\"Cote d' Or (Kraft)\", 2006, 1, 1.0),\n",
              " ('Cravve', 2012, 5, 3.3),\n",
              " ('Cravve', 2014, 2, 2.625),\n",
              " ('Creo', 2016, 2, 3.5),\n",
              " ('DAR', 2016, 3, 3.0),\n",
              " ('Daintree', 2011, 1, 3.25),\n",
              " ('Daintree', 2015, 1, 2.75),\n",
              " ('Dalloway', 2017, 1, 2.75),\n",
              " ('Damson', 2015, 4, 2.875),\n",
              " ('Dandelion', 2011, 3, 3.25),\n",
              " ('Dandelion', 2012, 3, 3.3333333333333335),\n",
              " ('Dandelion', 2013, 4, 3.25),\n",
              " ('Dandelion', 2014, 4, 3.375),\n",
              " ('Dandelion', 2015, 1, 3.0),\n",
              " ('Dandelion', 2016, 1, 3.75),\n",
              " ('Danta', 2009, 2, 3.125),\n",
              " ('Danta', 2011, 1, 3.5),\n",
              " ('Danta', 2012, 5, 3.55),\n",
              " ('Danta', 2014, 1, 3.25),\n",
              " ('Dark Forest', 2015, 4, 3.125),\n",
              " ('Dark Forest', 2016, 1, 3.25),\n",
              " ('Davis', 2012, 1, 3.25),\n",
              " ('Davis', 2013, 3, 2.6666666666666665),\n",
              " ('De Mendes', 2015, 2, 3.5),\n",
              " ('De Villiers', 2016, 2, 2.75),\n",
              " ('DeVries', 2007, 2, 3.5),\n",
              " ('DeVries', 2008, 1, 2.75),\n",
              " ('Dean and Deluca (Belcolade)', 2007, 6, 2.9166666666666665),\n",
              " ('Debauve & Gallais (Michel Cluizel)', 2008, 1, 3.75),\n",
              " ('Debauve & Gallais (Michel Cluizel)', 2009, 1, 3.0),\n",
              " ('Desbarres', 2016, 1, 2.5),\n",
              " ('Dick Taylor', 2011, 5, 2.95),\n",
              " ('Dick Taylor', 2012, 2, 2.75),\n",
              " ('Dick Taylor', 2013, 2, 3.375),\n",
              " ('Dick Taylor', 2014, 1, 3.5),\n",
              " ('Dick Taylor', 2015, 1, 3.75),\n",
              " ('Dick Taylor', 2016, 1, 3.5),\n",
              " ('Dick Taylor', 2017, 1, 3.75),\n",
              " ('Doble & Bignall', 2014, 3, 3.3333333333333335),\n",
              " ('Doble & Bignall', 2015, 1, 3.0),\n",
              " ('Dole (Guittard)', 2009, 1, 3.75),\n",
              " ('Dolfin (Belcolade)', 2006, 1, 1.5),\n",
              " ('Dolfin (Belcolade)', 2008, 1, 3.0),\n",
              " ('Domori', 2006, 3, 3.25),\n",
              " ('Domori', 2007, 8, 3.65625),\n",
              " ('Domori', 2008, 4, 3.3125),\n",
              " ('Domori', 2010, 1, 3.0),\n",
              " ('Domori', 2011, 1, 3.5),\n",
              " ('Domori', 2012, 2, 3.625),\n",
              " ('Domori', 2013, 1, 3.0),\n",
              " ('Domori', 2015, 2, 3.75),\n",
              " ('Dormouse', 2015, 3, 2.6666666666666665),\n",
              " ('Dormouse', 2016, 1, 2.75),\n",
              " (\"Duffy's\", 2010, 4, 3.375),\n",
              " (\"Duffy's\", 2011, 5, 3.4),\n",
              " (\"Duffy's\", 2012, 1, 3.75),\n",
              " (\"Duffy's\", 2014, 2, 3.625),\n",
              " (\"Duffy's\", 2015, 1, 4.0),\n",
              " ('Dulcinea', 2015, 1, 3.25),\n",
              " ('Durand', 2012, 1, 2.75),\n",
              " ('Durci', 2015, 5, 3.5),\n",
              " ('ENNA', 2016, 1, 3.25),\n",
              " ('East Van Roasters', 2014, 3, 3.5),\n",
              " ('Eau de Rose', 2016, 2, 3.25),\n",
              " ('Eclat (Felchlin)', 2012, 1, 2.75),\n",
              " ('Edelmond', 2016, 1, 3.0),\n",
              " ('El Ceibo', 2008, 1, 2.75),\n",
              " ('El Ceibo', 2011, 1, 3.75),\n",
              " ('El Rey', 2006, 1, 2.75),\n",
              " ('El Rey', 2008, 3, 2.6666666666666665),\n",
              " ('El Rey', 2009, 2, 2.875),\n",
              " ('El Rey', 2015, 1, 3.75),\n",
              " ('Emerald Estate', 2013, 2, 3.0),\n",
              " (\"Emily's\", 2015, 2, 3.25),\n",
              " ('Enric Rovira (Claudio Corallo)', 2010, 1, 3.25),\n",
              " ('Erithaj (A. Morin)', 2014, 3, 3.1666666666666665),\n",
              " ('Escazu', 2008, 1, 3.0),\n",
              " ('Escazu', 2009, 3, 2.75),\n",
              " ('Escazu', 2012, 1, 2.75),\n",
              " (\"Ethel's Artisan (Mars)\", 2011, 5, 2.55),\n",
              " ('Ethereal', 2014, 3, 3.4166666666666665),\n",
              " ('Fearless (AMMA)', 2010, 1, 2.75),\n",
              " ('Feitoria Cacao', 2016, 3, 2.75),\n",
              " ('Felchlin', 2006, 6, 3.0833333333333335),\n",
              " ('Felchlin', 2010, 1, 3.5),\n",
              " ('Finca', 2014, 4, 2.75),\n",
              " ('Forever Cacao', 2014, 1, 2.75),\n",
              " ('Forteza (Cortes)', 2016, 2, 2.75),\n",
              " ('Fossa', 2016, 3, 3.3333333333333335),\n",
              " ('Franceschi', 2012, 2, 3.625),\n",
              " ('Franceschi', 2014, 2, 3.625),\n",
              " ('Frederic Blondeel', 2014, 2, 3.5),\n",
              " ('Frederic Blondeel', 2015, 3, 3.3333333333333335),\n",
              " ('French Broad', 2011, 2, 3.5),\n",
              " ('French Broad', 2012, 3, 2.6666666666666665),\n",
              " ('French Broad', 2013, 1, 3.5),\n",
              " ('French Broad', 2014, 2, 3.125),\n",
              " ('French Broad', 2015, 1, 3.5),\n",
              " ('French Broad', 2017, 1, 3.5),\n",
              " ('Fresco', 2009, 4, 3.125),\n",
              " ('Fresco', 2011, 9, 3.25),\n",
              " ('Fresco', 2012, 5, 3.6),\n",
              " ('Fresco', 2013, 4, 3.6875),\n",
              " ('Fresco', 2014, 4, 3.375),\n",
              " ('Friis Holm', 2016, 1, 3.5),\n",
              " ('Friis Holm (Bonnat)', 2011, 3, 3.4166666666666665),\n",
              " ('Friis Holm (Bonnat)', 2012, 4, 3.375),\n",
              " ('Friis Holm (Bonnat)', 2013, 2, 3.375),\n",
              " ('Friis Holm (Bonnat)', 2014, 1, 3.5),\n",
              " ('Friis Holm (Bonnat)', 2015, 2, 3.125),\n",
              " ('Fruition', 2011, 2, 3.125),\n",
              " ('Fruition', 2012, 1, 2.5),\n",
              " ('Fruition', 2013, 2, 3.375),\n",
              " ('Fruition', 2014, 2, 3.375),\n",
              " ('Fruition', 2016, 2, 3.875),\n",
              " ('Garden Island', 2014, 1, 2.5),\n",
              " ('Georgia Ramon', 2015, 5, 3.55),\n",
              " ('Glennmade', 2015, 1, 3.0),\n",
              " ('Glennmade', 2016, 1, 3.5),\n",
              " ('Goodnow Farms', 2016, 3, 3.0833333333333335),\n",
              " ('Grand Place', 2011, 1, 3.0),\n",
              " (\"Green & Black's (ICAM)\", 2006, 1, 2.5),\n",
              " ('Green Bean to Bar', 2016, 1, 3.5),\n",
              " ('Grenada Chocolate Co.', 2008, 1, 2.5),\n",
              " ('Grenada Chocolate Co.', 2009, 1, 2.75),\n",
              " ('Grenada Chocolate Co.', 2010, 1, 3.25),\n",
              " ('Guido Castagna', 2009, 5, 3.05),\n",
              " ('Guittard', 2006, 6, 3.1666666666666665),\n",
              " ('Guittard', 2007, 1, 3.5),\n",
              " ('Guittard', 2008, 3, 3.1666666666666665),\n",
              " ('Guittard', 2009, 3, 3.1666666666666665),\n",
              " ('Guittard', 2010, 1, 3.0),\n",
              " ('Guittard', 2011, 3, 3.0833333333333335),\n",
              " ('Guittard', 2013, 4, 3.0625),\n",
              " ('Guittard', 2015, 1, 3.75),\n",
              " ('Habitual', 2014, 9, 2.9166666666666665),\n",
              " ('Hachez', 2007, 1, 2.5),\n",
              " ('Hacienda El Castillo', 2014, 2, 2.875),\n",
              " ('Haigh', 2011, 1, 3.0),\n",
              " ('Harper Macaw', 2015, 3, 3.3333333333333335),\n",
              " ('Harper Macaw', 2016, 1, 3.25),\n",
              " ('Heilemann', 2016, 1, 2.75),\n",
              " ('Heirloom Cacao Preservation (Brasstown)', 2016, 1, 3.25),\n",
              " ('Heirloom Cacao Preservation (Fruition)', 2016, 1, 3.5),\n",
              " ('Heirloom Cacao Preservation (Guittard)', 2014, 4, 3.5),\n",
              " ('Heirloom Cacao Preservation (Manoa)', 2016, 1, 3.5),\n",
              " ('Heirloom Cacao Preservation (Millcreek)', 2016, 1, 3.5),\n",
              " ('Heirloom Cacao Preservation (Mindo)', 2016, 1, 3.5),\n",
              " ('Heirloom Cacao Preservation (Zokoko)', 2016, 2, 3.875),\n",
              " ('Hogarth', 2016, 4, 3.0625),\n",
              " ('Hoja Verde (Tulicorp)', 2009, 5, 2.85),\n",
              " ('Holy Cacao', 2009, 4, 3.125),\n",
              " ('Holy Cacao', 2015, 4, 3.5),\n",
              " ('Holy Cacao', 2016, 1, 2.75),\n",
              " ('Honest', 2014, 1, 2.5),\n",
              " ('Hotel Chocolat', 2013, 2, 2.875),\n",
              " ('Hotel Chocolat', 2015, 1, 2.75),\n",
              " ('Hotel Chocolat (Coppeneur)', 2008, 4, 2.8125),\n",
              " ('Hotel Chocolat (Coppeneur)', 2010, 3, 2.8333333333333335),\n",
              " ('Hotel Chocolat (Coppeneur)', 2011, 3, 3.0833333333333335),\n",
              " ('Hotel Chocolat (Coppeneur)', 2012, 1, 3.5),\n",
              " ('Hotel Chocolat (Coppeneur)', 2013, 8, 3.0),\n",
              " ('Hummingbird', 2013, 2, 3.5),\n",
              " ('Hummingbird', 2014, 5, 3.25),\n",
              " ('Hummingbird', 2015, 1, 3.5),\n",
              " ('Idilio (Felchlin)', 2011, 9, 3.7777777777777777),\n",
              " ('Idilio (Felchlin)', 2013, 1, 3.75),\n",
              " ('Indah', 2016, 1, 2.5),\n",
              " ('Indaphoria', 2012, 2, 3.0),\n",
              " ('Indi', 2014, 1, 3.0),\n",
              " ('Isidro', 2014, 4, 3.0625),\n",
              " ('Izard', 2015, 2, 3.125),\n",
              " ('Jacque Torres', 2006, 1, 2.0),\n",
              " ('Jordis', 2015, 1, 2.75),\n",
              " ('Just Good Chocolate', 2014, 3, 3.6666666666666665),\n",
              " (\"K'ul\", 2016, 4, 3.375),\n",
              " ('Kah Kow', 2013, 4, 3.25),\n",
              " ('Kakao', 2009, 1, 3.75),\n",
              " ('Kakao', 2012, 1, 2.5),\n",
              " ('Kallari (Ecuatoriana)', 2008, 8, 2.875),\n",
              " ('Kaoka (Cemoi)', 2009, 2, 2.75),\n",
              " ('Kerchner', 2013, 1, 3.75),\n",
              " (\"Ki' Xocolatl\", 2009, 1, 2.0),\n",
              " ('Kiskadee', 2014, 1, 3.0),\n",
              " ('Kto', 2014, 7, 3.0357142857142856),\n",
              " ('Kyya', 2014, 4, 2.75),\n",
              " (\"L'Amourette\", 2012, 3, 3.0),\n",
              " (\"L'Amourette\", 2016, 1, 3.5),\n",
              " ('L.A. Burdick (Felchlin)', 2009, 2, 3.25),\n",
              " ('L.A. Burdick (Felchlin)', 2010, 3, 3.3333333333333335),\n",
              " ('L.A. Burdick (Felchlin)', 2011, 1, 3.75),\n",
              " ('L.A. Burdick (Felchlin)', 2012, 3, 3.6666666666666665),\n",
              " ('La Chocolaterie Nanairo', 2016, 4, 2.6875),\n",
              " ('La Maison du Chocolat (Valrhona)', 2008, 1, 3.5),\n",
              " ('La Maison du Chocolat (Valrhona)', 2009, 4, 3.375),\n",
              " ('La Maison du Chocolat (Valrhona)', 2011, 1, 3.5),\n",
              " ('La Maison du Chocolat (Valrhona)', 2012, 1, 3.5),\n",
              " ('La Maison du Chocolat (Valrhona)', 2013, 3, 3.0833333333333335),\n",
              " ('La Oroquidea', 2011, 1, 2.5),\n",
              " ('La Pepa de Oro', 2011, 1, 3.25),\n",
              " ('Laia aka Chat-Noir', 2014, 2, 2.75),\n",
              " ('Laia aka Chat-Noir', 2015, 8, 3.15625),\n",
              " ('Lajedo do Ouro', 2012, 1, 3.5),\n",
              " ('Lake Champlain (Callebaut)', 2009, 1, 2.5),\n",
              " ('Letterpress', 2014, 1, 3.5),\n",
              " ('Letterpress', 2015, 5, 3.3),\n",
              " ('Letterpress', 2016, 1, 3.25),\n",
              " ('Letterpress', 2017, 2, 3.375),\n",
              " ('Levy', 2014, 1, 3.5),\n",
              " ('Lilla', 2016, 1, 3.0),\n",
              " ('Lillie Belle', 2012, 6, 3.3333333333333335),\n",
              " ('Lindt & Sprungli', 2007, 1, 3.0),\n",
              " ('Loiza', 2013, 1, 2.5),\n",
              " ('Lonohana', 2013, 3, 3.1666666666666665),\n",
              " ('Lonohana', 2014, 3, 3.5833333333333335),\n",
              " ('Love Bar', 2015, 1, 2.0),\n",
              " ('Luker', 2010, 4, 3.0625),\n",
              " ('Machu Picchu Trading Co.', 2010, 1, 2.25),\n",
              " ('Machu Picchu Trading Co.', 2011, 1, 1.5),\n",
              " ('Madecasse (Cinagra)', 2008, 4, 3.6875),\n",
              " ('Madre', 2010, 1, 2.75),\n",
              " ('Madre', 2011, 2, 2.625),\n",
              " ('Madre', 2012, 3, 3.3333333333333335),\n",
              " ('Madre', 2013, 4, 2.9375),\n",
              " ('Madre', 2017, 1, 3.5),\n",
              " ('Maglio', 2008, 4, 3.0),\n",
              " ('Majani', 2010, 1, 2.0),\n",
              " ('Malagasy (Chocolaterie Robert)', 2007, 2, 3.125),\n",
              " ('Malagos', 2013, 1, 3.5),\n",
              " ('Malie Kai (Guittard)', 2009, 1, 2.75),\n",
              " ('Malie Kai (Guittard)', 2010, 1, 3.5),\n",
              " ('Malmo', 2016, 1, 3.0),\n",
              " ('Mana', 2012, 1, 3.75),\n",
              " ('Mana', 2014, 2, 2.625),\n",
              " ('Mana', 2015, 1, 2.5),\n",
              " ('Manifesto Cacao', 2014, 1, 2.75),\n",
              " ('Manoa', 2012, 4, 3.0625),\n",
              " ('Manoa', 2013, 1, 3.75),\n",
              " ('Manoa', 2015, 2, 3.625),\n",
              " ('Manufaktura Czekolady', 2012, 3, 3.3333333333333335),\n",
              " ('Manufaktura Czekolady', 2014, 2, 3.625),\n",
              " ('Manufaktura Czekolady', 2016, 2, 3.625),\n",
              " ('Map Chocolate', 2015, 9, 3.2777777777777777),\n",
              " ('Map Chocolate', 2016, 1, 3.25),\n",
              " ('Marana', 2016, 3, 2.9166666666666665),\n",
              " (\"Marigold's Finest\", 2016, 1, 3.25),\n",
              " ('Marou', 2012, 6, 3.4166666666666665),\n",
              " ('Marou', 2013, 1, 3.5),\n",
              " ('Marou', 2015, 3, 3.5),\n",
              " ('Mars', 2010, 4, 3.1875),\n",
              " ('Marsatta', 2013, 2, 2.375),\n",
              " ('Martin Mayer', 2016, 3, 3.0),\n",
              " ('Mast Brothers', 2010, 3, 3.0),\n",
              " ('Mast Brothers', 2011, 9, 3.1666666666666665),\n",
              " ('Mast Brothers', 2012, 3, 2.9166666666666665),\n",
              " ('Mast Brothers', 2014, 1, 3.75),\n",
              " ('Mast Brothers', 2015, 2, 3.125),\n",
              " ('Matale', 2013, 4, 3.8125),\n",
              " ('Maverick', 2014, 4, 3.3125),\n",
              " ('Mayacama', 2016, 1, 3.0),\n",
              " ('Meadowlands', 2014, 5, 2.95),\n",
              " ('Menakao (aka Cinagra)', 2012, 2, 2.5),\n",
              " ('Mesocacao', 2014, 4, 3.375),\n",
              " ('Mesocacao', 2015, 2, 2.875),\n",
              " ('Metiisto', 2014, 2, 3.25),\n",
              " ('Metropolitan', 2015, 1, 3.5),\n",
              " ('Michel Cluizel', 2006, 7, 3.0),\n",
              " ('Michel Cluizel', 2007, 2, 3.5),\n",
              " ('Michel Cluizel', 2012, 1, 3.75),\n",
              " ('Middlebury', 2012, 3, 2.0),\n",
              " ('Middlebury', 2013, 2, 2.875),\n",
              " ('Middlebury', 2015, 6, 3.5416666666666665),\n",
              " ('Millcreek Cacao Roasters', 2012, 1, 3.5),\n",
              " ('Millcreek Cacao Roasters', 2013, 1, 2.5),\n",
              " ('Mindo', 2010, 2, 2.75),\n",
              " ('Minimal', 2016, 1, 3.5),\n",
              " ('Mission', 2015, 1, 3.5),\n",
              " ('Mission', 2016, 1, 3.75),\n",
              " ('Mita', 2012, 1, 2.5),\n",
              " ('Moho', 2010, 1, 2.75),\n",
              " ('Moho', 2013, 2, 3.125),\n",
              " ('Molucca', 2015, 3, 3.0),\n",
              " ('Momotombo', 2011, 3, 2.9166666666666665),\n",
              " ('Monarque', 2016, 1, 3.5),\n",
              " ('Monsieur Truffe', 2014, 1, 3.25),\n",
              " ('Montecristi', 2015, 3, 3.4166666666666665),\n",
              " ('Muchomas (Mesocacao)', 2015, 2, 3.5),\n",
              " ('Mutari', 2016, 4, 2.8125),\n",
              " ('Nahua', 2013, 2, 2.75),\n",
              " ('Naive', 2012, 1, 2.5),\n",
              " ('Naive', 2013, 2, 3.75),\n",
              " ('Nanea', 2013, 1, 3.5),\n",
              " ('Nathan Miller', 2014, 4, 2.6875),\n",
              " ('Na�ve', 2014, 3, 3.0),\n",
              " ('Neuhaus (Callebaut)', 2006, 3, 2.5833333333333335),\n",
              " ('Neuhaus (Callebaut)', 2007, 1, 1.0),\n",
              " ('Neuhaus (Callebaut)', 2008, 1, 3.75),\n",
              " ('Neuhaus (Callebaut)', 2010, 1, 2.5),\n",
              " ('Nibble', 2015, 4, 2.75),\n",
              " ('Night Owl', 2013, 2, 3.125),\n",
              " ('Noble Bean aka Jerjobo', 2014, 3, 3.0833333333333335),\n",
              " (\"Noir d' Ebine\", 2012, 2, 3.0),\n",
              " ('Nova Monda', 2012, 3, 3.0),\n",
              " ('Nuance', 2015, 5, 3.35),\n",
              " ('Nugali', 2016, 1, 3.5),\n",
              " ('Oakland Chocolate Co.', 2010, 1, 2.5),\n",
              " ('Obolo', 2015, 2, 3.75),\n",
              " ('Ocelot', 2015, 2, 3.875),\n",
              " ('Ocho', 2014, 4, 3.125),\n",
              " ('Ocho', 2016, 2, 3.125),\n",
              " ('Ohiyo', 2015, 2, 2.875),\n",
              " ('Oialla by Bojessen (Malmo)', 2011, 1, 3.5),\n",
              " ('Olive and Sinclair', 2009, 2, 2.875),\n",
              " ('Olive and Sinclair', 2010, 2, 3.0),\n",
              " ('Olivia', 2011, 4, 2.625),\n",
              " ('Omanhene', 2011, 1, 2.75),\n",
              " ('Omnom', 2014, 2, 3.25),\n",
              " ('Omnom', 2016, 1, 3.75),\n",
              " ('Original Beans (Felchlin)', 2009, 3, 3.0833333333333335),\n",
              " ('Original Beans (Felchlin)', 2011, 1, 3.75),\n",
              " ('Original Beans (Felchlin)', 2014, 2, 3.0),\n",
              " ('Original Hawaiin Chocolate Factory', 2006, 1, 3.0),\n",
              " ('Original Hawaiin Chocolate Factory', 2009, 1, 3.0),\n",
              " ('Orquidea', 2012, 2, 3.0),\n",
              " ('Pacari', 2008, 5, 2.75),\n",
              " ('Pacari', 2011, 1, 3.5),\n",
              " ('Pacari', 2012, 2, 3.375),\n",
              " ('Pacari', 2014, 4, 3.625),\n",
              " ('Pacari', 2016, 1, 4.0),\n",
              " ('Palette de Bine', 2014, 5, 3.3),\n",
              " ('Palette de Bine', 2015, 4, 3.4375),\n",
              " ('Palette de Bine', 2016, 2, 2.875),\n",
              " ('Pangea', 2016, 1, 3.0),\n",
              " ('Park 75', 2014, 1, 3.5),\n",
              " ('Parliament', 2014, 2, 3.25),\n",
              " ('Parliament', 2015, 1, 3.5),\n",
              " ('Parliament', 2016, 1, 3.25),\n",
              " ('Pascha', 2013, 2, 2.625),\n",
              " ('Patric', 2007, 1, 4.0),\n",
              " ('Patric', 2009, 3, 3.6666666666666665),\n",
              " ('Patric', 2011, 1, 3.75),\n",
              " ('Patric', 2013, 1, 4.0),\n",
              " ('Paul Young', 2014, 2, 2.5),\n",
              " ('Peppalo', 2015, 1, 3.0),\n",
              " ('Pierre Marcolini', 2006, 3, 3.6666666666666665),\n",
              " ('Pierre Marcolini', 2007, 4, 3.8125),\n",
              " ('Pierre Marcolini', 2009, 2, 3.0),\n",
              " ('Pierre Marcolini', 2010, 4, 3.25),\n",
              " ('Pierre Marcolini', 2015, 1, 3.25),\n",
              " ('Pinellas', 2016, 1, 2.5),\n",
              " ('Pitch Dark', 2014, 4, 3.125),\n",
              " ('Pitch Dark', 2015, 5, 2.8),\n",
              " ('Pomm (aka Dead Dog)', 2012, 2, 2.625),\n",
              " ('Potomac', 2010, 1, 3.75),\n",
              " ('Potomac', 2011, 4, 3.1875),\n",
              " ('Potomac', 2014, 1, 3.75),\n",
              " ('Potomac', 2016, 1, 3.75),\n",
              " ('Pralus', 2006, 16, 3.40625),\n",
              " ('Pralus', 2007, 1, 4.0),\n",
              " ('Pralus', 2008, 4, 2.875),\n",
              " ('Pralus', 2009, 1, 2.0),\n",
              " ('Pralus', 2010, 1, 3.5),\n",
              " ('Pralus', 2011, 1, 3.25),\n",
              " ('Pralus', 2015, 1, 3.25),\n",
              " ('Pump Street Bakery', 2014, 4, 2.9375),\n",
              " ('Pump Street Bakery', 2015, 3, 3.25),\n",
              " ('Pump Street Bakery', 2016, 1, 3.5),\n",
              " ('Pura Delizia', 2012, 1, 2.75),\n",
              " ('Q Chocolate', 2012, 2, 3.125),\n",
              " ('Q Chocolate', 2013, 4, 3.1875),\n",
              " ('Quetzalli (Wolter)', 2016, 2, 2.875),\n",
              " ('Raaka', 2011, 1, 3.5),\n",
              " ('Raaka', 2012, 1, 3.25),\n",
              " ('Raaka', 2015, 1, 2.75),\n",
              " ('Raaka', 2016, 1, 3.0),\n",
              " ('Rain Republic', 2010, 1, 2.75),\n",
              " ('Rancho San Jacinto', 2010, 1, 3.0),\n",
              " ('Ranger', 2015, 3, 3.0833333333333335),\n",
              " ('Raoul Boulanger', 2016, 1, 3.25),\n",
              " ('Raw Cocoa', 2012, 1, 2.5),\n",
              " ('Republica del Cacao (aka Confecta)', 2007, 3, 3.4166666666666665),\n",
              " ('Republica del Cacao (aka Confecta)', 2009, 1, 2.5),\n",
              " ('Republica del Cacao (aka Confecta)', 2010, 1, 3.25),\n",
              " ('Ritual', 2011, 1, 3.5),\n",
              " ('Ritual', 2012, 3, 3.5833333333333335),\n",
              " ('Ritual', 2013, 2, 3.375),\n",
              " ('Ritual', 2015, 2, 3.5),\n",
              " ('Ritual', 2016, 1, 3.75),\n",
              " ('Roasting Masters', 2016, 3, 3.25),\n",
              " ('Robert (aka Chocolaterie Robert)', 2013, 2, 3.25),\n",
              " ('Rococo (Grenada Chocolate Co.)', 2012, 1, 3.5),\n",
              " ('Rogue', 2008, 4, 2.8125),\n",
              " ('Rogue', 2009, 1, 3.5),\n",
              " ('Rogue', 2010, 1, 3.75),\n",
              " ('Rogue', 2011, 1, 3.0),\n",
              " ('Rogue', 2012, 1, 3.75),\n",
              " ('Rogue', 2013, 4, 3.6875),\n",
              " ('Rogue', 2014, 1, 3.75),\n",
              " ('Rogue', 2015, 2, 3.5),\n",
              " ('Rogue', 2016, 1, 3.75),\n",
              " ('Rozsavolgyi', 2011, 4, 3.0625),\n",
              " ('Rozsavolgyi', 2012, 3, 2.4166666666666665),\n",
              " ('S.A.I.D.', 2010, 5, 3.0),\n",
              " ('SRSLY', 2013, 2, 2.625),\n",
              " ('Sacred', 2012, 2, 3.0),\n",
              " ('Salgado', 2008, 4, 3.5),\n",
              " ('Santander (Compania Nacional)', 2006, 3, 3.0),\n",
              " ('Santander (Compania Nacional)', 2009, 2, 2.875),\n",
              " ('Santome', 2011, 1, 2.75),\n",
              " ('Scharffen Berger', 2006, 5, 2.5),\n",
              " ('Scharffen Berger', 2007, 4, 3.1875),\n",
              " ('Scharffen Berger', 2008, 1, 3.0),\n",
              " ('Scharffen Berger', 2009, 3, 3.8333333333333335),\n",
              " ('Scharffen Berger', 2010, 2, 3.625),\n",
              " ('Scharffen Berger', 2011, 1, 3.75),\n",
              " ('Scharffen Berger', 2012, 1, 4.0),\n",
              " ('Seaforth', 2015, 2, 2.75),\n",
              " ('Shark Mountain', 2014, 2, 3.125),\n",
              " ('Shark Mountain', 2015, 4, 3.25),\n",
              " (\"Shark's\", 2011, 2, 2.25),\n",
              " ('Shattel', 2016, 1, 3.25),\n",
              " ('Shattell', 2011, 1, 3.5),\n",
              " ('Sibu', 2015, 2, 3.375),\n",
              " ('Sibu Sura', 2012, 1, 2.5),\n",
              " ('Silvio Bessone', 2011, 4, 3.125),\n",
              " ('Sirene', 2014, 3, 3.75),\n",
              " ('Sirene', 2015, 5, 3.1),\n",
              " ('Sirene', 2016, 3, 3.5833333333333335),\n",
              " ('Sjolinds', 2015, 2, 2.875),\n",
              " ('Smooth Chocolator, The', 2015, 9, 3.4722222222222223),\n",
              " ('Smooth Chocolator, The', 2016, 6, 3.5833333333333335),\n",
              " ('Smooth Chocolator, The', 2017, 1, 3.5),\n",
              " ('Snake & Butterfly', 2010, 2, 3.125),\n",
              " ('Snake & Butterfly', 2011, 1, 1.5),\n",
              " ('Sol Cacao', 2015, 1, 3.0),\n",
              " ('Sol Cacao', 2016, 1, 3.5),\n",
              " ('Solkiki', 2016, 2, 2.75),\n",
              " ('Solomons Gold', 2016, 2, 3.25),\n",
              " ('Solstice', 2013, 5, 3.2),\n",
              " ('Solstice', 2014, 1, 3.0),\n",
              " ('Soma', 2009, 6, 3.4166666666666665),\n",
              " ('Soma', 2010, 1, 3.75),\n",
              " ('Soma', 2011, 6, 3.5833333333333335),\n",
              " ('Soma', 2012, 8, 3.65625),\n",
              " ('Soma', 2013, 11, 3.6136363636363638),\n",
              " ('Soma', 2014, 6, 3.5),\n",
              " ('Soma', 2015, 2, 3.75),\n",
              " ('Soma', 2016, 7, 3.607142857142857),\n",
              " ('Somerville', 2014, 2, 3.375),\n",
              " ('Soul', 2017, 6, 3.375),\n",
              " ('Spagnvola', 2012, 3, 3.0833333333333335),\n",
              " ('Spencer', 2014, 1, 2.75),\n",
              " ('Spencer', 2016, 3, 3.6666666666666665),\n",
              " ('Spencer', 2017, 3, 3.3333333333333335),\n",
              " ('Sprungli (Felchlin)', 2013, 1, 3.0),\n",
              " ('StRita Supreme', 2012, 3, 2.5833333333333335),\n",
              " ('Starchild', 2015, 5, 3.0),\n",
              " ('Stella (aka Bernrain)', 2011, 1, 3.25),\n",
              " ('Stella (aka Bernrain)', 2012, 1, 2.75),\n",
              " ('Stone Grindz', 2014, 2, 3.5),\n",
              " ('Sublime Origins', 2013, 2, 3.0),\n",
              " ('Summerbird', 2016, 2, 2.75),\n",
              " ('Suruca Chocolate', 2016, 2, 2.875),\n",
              " ('Svenska Kakaobolaget', 2015, 1, 2.75),\n",
              " ('Szanto Tibor', 2011, 1, 3.0),\n",
              " ('Szanto Tibor', 2012, 3, 3.4166666666666665),\n",
              " ('Szanto Tibor', 2013, 3, 3.4166666666666665),\n",
              " ('Szanto Tibor', 2014, 2, 3.625),\n",
              " ('Szanto Tibor', 2015, 6, 3.375),\n",
              " ('TCHO', 2008, 4, 2.5625),\n",
              " ('TCHO', 2009, 2, 2.875),\n",
              " ('TCHO', 2012, 1, 3.25),\n",
              " ('TCHO', 2016, 1, 2.0),\n",
              " ('Tabal', 2013, 4, 2.75),\n",
              " ('Tablette (aka Vanillabeans)', 2015, 4, 3.0625),\n",
              " ('Tan Ban Skrati', 2016, 1, 3.25),\n",
              " ('Taza', 2007, 1, 3.0),\n",
              " ('Taza', 2009, 1, 2.75),\n",
              " ('Taza', 2011, 1, 3.25),\n",
              " ('Taza', 2014, 1, 3.0),\n",
              " ('Tejas', 2012, 14, 3.017857142857143),\n",
              " ('Terroir', 2014, 3, 3.5833333333333335),\n",
              " ('Terroir', 2015, 6, 3.4583333333333335),\n",
              " ('The Barn', 2015, 1, 3.0),\n",
              " ('Theo', 2007, 5, 2.8),\n",
              " ('Theo', 2012, 1, 3.25),\n",
              " ('Theobroma', 2015, 1, 3.25),\n",
              " ('Timo A. Meyer', 2016, 1, 3.75),\n",
              " (\"To'ak (Ecuatoriana)\", 2014, 1, 3.25),\n",
              " ('Tobago Estate (Pralus)', 2012, 1, 4.0),\n",
              " ('Tocoti', 2011, 2, 2.875),\n",
              " ('Tocoti', 2012, 1, 3.0),\n",
              " ('Treehouse', 2014, 1, 3.0),\n",
              " ('Tsara (Cinagra)', 2011, 1, 3.5),\n",
              " ('Two Ravens', 2016, 1, 3.0),\n",
              " ('Un Dimanche A Paris', 2011, 1, 3.75),\n",
              " ('Undone', 2014, 2, 2.875),\n",
              " ('Upchurch', 2016, 2, 3.125),\n",
              " ('Urzi', 2014, 1, 3.25),\n",
              " ('Valrhona', 2006, 5, 3.2),\n",
              " ('Valrhona', 2007, 7, 2.9642857142857144),\n",
              " ('Valrhona', 2009, 3, 3.6666666666666665),\n",
              " ('Valrhona', 2011, 2, 3.625),\n",
              " ('Valrhona', 2012, 1, 4.0),\n",
              " ('Valrhona', 2013, 2, 3.5),\n",
              " ('Valrhona', 2015, 1, 4.0),\n",
              " ('Vanleer (Barry Callebaut)', 2012, 2, 2.625),\n",
              " ('Vao Vao (Chocolaterie Robert)', 2009, 6, 2.9166666666666665),\n",
              " ('Vicuna', 2015, 2, 3.25),\n",
              " ('Videri', 2012, 1, 3.25),\n",
              " ('Videri', 2013, 1, 3.75),\n",
              " ('Videri', 2014, 3, 3.4166666666666665),\n",
              " ('Vietcacao (A. Morin)', 2012, 1, 3.5),\n",
              " ('Vintage Plantations', 2014, 1, 3.0),\n",
              " ('Vintage Plantations (Tulicorp)', 2007, 4, 2.5),\n",
              " ('Violet Sky', 2015, 5, 2.95),\n",
              " ('Vivra', 2016, 3, 2.6666666666666665),\n",
              " ('Wellington Chocolate Factory', 2016, 2, 3.5),\n",
              " ('Whittakers', 2011, 1, 2.5),\n",
              " (\"Wilkie's Organic\", 2013, 4, 2.8125),\n",
              " (\"Willie's Cacao\", 2009, 2, 3.125),\n",
              " (\"Willie's Cacao\", 2010, 3, 3.4166666666666665),\n",
              " (\"Willie's Cacao\", 2013, 1, 2.25),\n",
              " (\"Willie's Cacao\", 2014, 1, 3.0),\n",
              " (\"Willie's Cacao\", 2016, 1, 4.0),\n",
              " ('Wm', 2016, 3, 3.4166666666666665),\n",
              " ('Woodblock', 2011, 2, 3.75),\n",
              " ('Woodblock', 2012, 3, 2.9166666666666665),\n",
              " ('Woodblock', 2013, 2, 3.375),\n",
              " ('Woodblock', 2014, 1, 3.0),\n",
              " ('Xocolat', 2013, 1, 3.0),\n",
              " ('Xocolla', 2017, 2, 2.625),\n",
              " (\"Zak's\", 2015, 6, 3.2083333333333335),\n",
              " ('Zart Pralinen', 2016, 6, 3.1666666666666665),\n",
              " ('Zokoko', 2011, 3, 3.5833333333333335),\n",
              " ('Zokoko', 2016, 2, 3.5),\n",
              " ('Zotter', 2010, 1, 3.0),\n",
              " ('Zotter', 2011, 4, 3.375),\n",
              " ('Zotter', 2012, 11, 3.3636363636363638),\n",
              " ('Zotter', 2014, 1, 2.75),\n",
              " ('hello cocoa', 2015, 2, 3.125),\n",
              " ('hexx', 2015, 5, 3.05),\n",
              " ('iQ Chocolate', 2012, 2, 2.875),\n",
              " ('organicfair', 2013, 5, 2.85),\n",
              " ('twenty-four blackbirds', 2011, 1, 2.75),\n",
              " ('twenty-four blackbirds', 2013, 2, 2.875),\n",
              " ('twenty-four blackbirds', 2014, 1, 3.5),\n",
              " ('twenty-four blackbirds', 2015, 2, 3.125)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnJR4sgy8b8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! rm -rf choco_flavors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKx7_9vyYCy1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# 3. Kickstarter Projects Dataset (25pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HXua9B5YCy2",
        "colab_type": "text"
      },
      "source": [
        "Using the [Kickstarter Projects Dataset](https://www.kaggle.com/kemical/kickstarter-projects#ks-projects-201801.csv), answer the following questions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGgJ1dyeZiFH",
        "colab_type": "text"
      },
      "source": [
        "**Task 1 (for everyone):** Load the dataset to SQLite DB using [PonyORM](https://ponyorm.org) (10pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLhhxMDDb2nN",
        "colab_type": "code",
        "outputId": "ac3d06dd-1441-4869-a03e-04c05847a715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "!kaggle datasets list -s kickstarter-projects\n",
        "!kaggle datasets download kemical/kickstarter-projects -p ./datasets/kickstarter-projects/\n",
        "!unzip ./datasets/kickstarter-projects/*.zip  -d ./datasets/kickstarter-projects/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                              title                                        size  lastUpdated          downloadCount  \n",
            "-----------------------------------------------  ------------------------------------------  -----  -------------------  -------------  \n",
            "kemical/kickstarter-projects                     Kickstarter Projects                         37MB  2018-02-08 09:02:30          35064  \n",
            "codename007/funding-successful-projects          Funding Successful Projects on Kickstarter   20MB  2017-06-20 17:37:38           2419  \n",
            "socathie/kickstarter-project-statistics          Kickstarter Project Statistics                1MB  2019-11-14 06:38:31           5336  \n",
            "toshimelonhead/400000-kickstarter-projects       400,000 Kickstarter Projects                   0B  2019-07-23 01:23:31            145  \n",
            "uysalah/archived-kickstarter-projects            Archived Kickstarter Projects                 1MB  2019-05-10 04:33:22            125  \n",
            "yashkantharia/kickstarter-campaigns              Kickstarter Campaigns                        12MB  2019-03-03 13:46:08            442  \n",
            "oscarvilla/kickstarter-nlp                       kickstarter NLP                              11MB  2018-08-09 01:38:57            207  \n",
            "tonyplaysguitar/steam-spy-data-from-api-request  Kickstarter videogames released on Steam      1MB  2018-01-21 23:54:08            231  \n",
            "officerbribe/yks-six-pack                        YKS Six Pack                                147KB  2020-03-05 17:49:58             55  \n",
            "wood2174/mapkickstarter                          Kickstarter                                  18MB  2018-03-07 00:01:12            212  \n",
            "antonionoca/kickstarter2018nlp                   kickstarter-2018-nlp                         35MB  2019-04-23 22:02:34             65  \n",
            "alonsopuente/kickstarter-projects-images         Kickstarter_projects_images                   2GB  2019-11-02 04:14:00             67  \n",
            "alonsopuente/kickstarter-projects-descriptions   kickstarter_projects_descriptions            35MB  2019-11-15 06:37:59             23  \n",
            "alonsopuente/kickstarter-projects-metadata       kickstarter_projects_metadata                 5MB  2019-11-15 06:27:11             32  \n",
            "skhadirahmed/redditdataset                       reddit-dataset                              616MB  2019-03-01 08:09:26             22  \n",
            "Downloading kickstarter-projects.zip to ./datasets/kickstarter-projects\n",
            " 84% 31.0M/36.8M [00:00<00:00, 15.7MB/s]\n",
            "100% 36.8M/36.8M [00:01<00:00, 38.0MB/s]\n",
            "Archive:  ./datasets/kickstarter-projects/kickstarter-projects.zip\n",
            "  inflating: ./datasets/kickstarter-projects/ks-projects-201612.csv  \n",
            "  inflating: ./datasets/kickstarter-projects/ks-projects-201801.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrHNoOxvDKSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! rm -rf /content/datasets/kickstarter-projects/kickstarter-project.pony.db"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEMfGmMw_oO-",
        "colab_type": "code",
        "outputId": "9d8504f2-9212-425c-c19d-42190b800de8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from pony.orm import *\n",
        "# Creating a new database\n",
        "db_ks = Database()\n",
        "db_ks.bind(provider='sqlite', filename='/content/datasets/kickstarter-projects/kickstarter-project.pony.db', create_db=True)\n",
        "\n",
        "class KickstarterProject(db_ks.Entity):\n",
        "    name = Optional(str) \n",
        "    category = Required(str)\n",
        "    main_category = Required(str)\n",
        "    currency = Required(str)\n",
        "    deadline = Required(str)\n",
        "    goal = Required(float)\n",
        "    launched = Required(str)\n",
        "    pledged = Required(float)\n",
        "    launched = Required(str)\n",
        "    state = Required(str)\n",
        "    backers = Required(int)\n",
        "    country = Required(str)\n",
        "    usd_pledged = Optional(float)\n",
        "    usd_pledged_real = Required(float)\n",
        "    usd_goal_real = Required(float)\n",
        "\n",
        "show(KickstarterProject)\n",
        "#set_sql_debug(True) # helps to see what SQL commands are running\n",
        "db_ks.generate_mapping(create_tables=True) # create tables"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class KickstarterProject(Entity):\n",
            "    id = PrimaryKey(int, auto=True)\n",
            "    name = Optional(str, default='')\n",
            "    category = Required(str)\n",
            "    main_category = Required(str)\n",
            "    currency = Required(str)\n",
            "    deadline = Required(str)\n",
            "    goal = Required(float)\n",
            "    pledged = Required(float)\n",
            "    launched = Required(str)\n",
            "    state = Required(str)\n",
            "    backers = Required(int)\n",
            "    country = Required(str)\n",
            "    usd_pledged = Optional(float)\n",
            "    usd_pledged_real = Required(float)\n",
            "    usd_goal_real = Required(float)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t98KAI3aAUwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "\n",
        "df_ks = pandas.read_csv(\"./datasets/kickstarter-projects/ks-projects-201801.csv\")\n",
        "df_ks['name'].fillna(\"\", inplace=True)\n",
        "df_ks['usd pledged'].fillna(0.0, inplace=True)\n",
        "\n",
        "for idx, row in df_ks.iterrows():\n",
        "    KickstarterProject(\n",
        "            name=(row['name'] if not type(row['name']) is float else \"\"),\n",
        "            category=row['category'],\n",
        "            main_category=row['main_category'],\n",
        "            currency=row['currency'],\n",
        "            deadline=row['deadline'],\n",
        "            goal=row['goal'],\n",
        "            launched=row['launched'],\n",
        "            pledged=row['pledged'],\n",
        "            state=row['state'],\n",
        "            backers=row['backers'],\n",
        "            country=row['country'],\n",
        "            usd_pledged=row['usd pledged'],\n",
        "            usd_pledged_real=row['usd_pledged_real'],\n",
        "            usd_goal_real=row['usd_goal_real'],\n",
        "    )\n",
        "commit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1K5VTLoYCy3",
        "colab_type": "text"
      },
      "source": [
        "### <span style=\"color:red\"> Please answer only **one** of the following questions according to your ID number (use the formula **<YOUR_ID> mod 3 +1**) </span>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwlOZtVHYCy3",
        "colab_type": "code",
        "outputId": "e323aada-e564-4f5f-c6dd-5867010e946e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# which question to answer - put your ID number and run the code \n",
        "your_id  = \"316460443\"\n",
        "q = int(your_id) % 3 + 1\n",
        "print(\"You need to answer question number %s\" % q)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You need to answer question number 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkVN8OnxYCy5",
        "colab_type": "text"
      },
      "source": [
        "**Question 1:** On average which project category received the highest number of backers? (15 pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkhb156oYCy6",
        "colab_type": "code",
        "outputId": "6e54e69f-c49b-40cf-ffd7-2d6d46d708bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\n",
            "drwxr-xr-x 1 root root 4096 Mar 18 16:23 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTk5XnNGYCy7",
        "colab_type": "text"
      },
      "source": [
        "**Question 2:** On average which project category received the highest pledged USD? (15 pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfiXdIneYCy8",
        "colab_type": "code",
        "outputId": "52687eb5-9461-42b2-9967-59a82b9125d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "\"\"\"\n",
        "    SELECT \"p\".\"category\", AVG(\"p\".\"usd_pledged\")\n",
        "    FROM \"KickstarterProject\" \"p\"\n",
        "    GROUP BY \"p\".\"category\"\n",
        "\"\"\"\n",
        "avg_pledge = select((p.category, avg(p.usd_pledged)) for p in KickstarterProject)\n",
        "\n",
        "\"\"\"\n",
        "    ORDER BY AVG(\"p\".\"usd_pledged\") DESC\n",
        "    LIMIT 1\n",
        "\"\"\"\n",
        "desc_avg_pledge = avg_pledge.order_by(lambda x,y: desc(y)).limit(1)\n",
        "list(desc_avg_pledge)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SELECT \"p\".\"category\", AVG(\"p\".\"usd_pledged\")\n",
            "FROM \"KickstarterProject\" \"p\"\n",
            "GROUP BY \"p\".\"category\"\n",
            "ORDER BY AVG(\"p\".\"usd_pledged\") DESC\n",
            "LIMIT 1\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('3D Printing', 52027.158213762814)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM5KvHE1YCy9",
        "colab_type": "text"
      },
      "source": [
        "**Question 3:** In which month occurred the highest number of projects? (15 pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DTIStGMYCy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ResaA3kxYCy_",
        "colab_type": "text"
      },
      "source": [
        "## 4. Oscars Datasets (10pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYQasQOKYCzA",
        "colab_type": "text"
      },
      "source": [
        "Using the [Oscars Dataset](https://www.kaggle.com/theacademy/academy-awards), please answer only one of the following questions (you can chose):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGDmLdbKYCzA",
        "colab_type": "text"
      },
      "source": [
        "**Question 1:** Who is the female actress with the most Oscar nominees? (10pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR33wDkbYCzD",
        "colab_type": "text"
      },
      "source": [
        "**Question 2:** Who is the male director with the most Oscar nominees? (10pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qipeHl6AYCzB",
        "colab_type": "code",
        "outputId": "e8f23ed0-748a-49e1-a945-c27b4447f966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# download and unzip dataset\n",
        "!kaggle datasets list -s academy-awards\n",
        "!kaggle datasets download theacademy/academy-awards -p ./datasets/academy-awards/\n",
        "!unzip ./datasets/academy-awards/academy-awards.zip -d ./datasets/academy-awards/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                     title                                                size  lastUpdated          downloadCount  \n",
            "------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  \n",
            "theacademy/academy-awards                               The Academy Awards, 1927-2015                       185KB  2017-02-13 17:30:48           4881  \n",
            "fmejia21/demographics-of-academy-awards-oscars-winners  Demographics of Academy Awards (Oscars) Winners      20KB  2020-02-04 17:38:26           2138  \n",
            "unanimad/golden-globe-awards                            Golden Globe Awards, 1944 - 2020                    117KB  2020-01-06 16:19:01           1551  \n",
            "unanimad/the-oscar-award                                The Oscar Award, 1927 - 2020                        191KB  2020-02-19 15:45:30            552  \n",
            "madhurinani/oscars-2017-tweets                          2017 #Oscars Tweets                                  11MB  2017-03-17 19:50:40            357  \n",
            "unanimad/grammy-awards                                  Grammy Awards                                       185KB  2019-12-26 13:15:21            118  \n",
            "alexis333/academy-awards-cleanup                        Academy Awards Cleanup                              178KB  2019-03-25 18:19:58             39  \n",
            "unanimad/bafta-awards                                   British Academy of Film and Television Arts Awards   74KB  2020-02-04 11:35:02             35  \n",
            "pmagda/primetime-emmy-awards                            Primetime Emmy Awards, 1949-2017                    235KB  2017-09-19 16:15:31            367  \n",
            "unanimad/emmy-awards                                    Emmy Awards                                         904KB  2020-01-02 23:54:37             46  \n",
            "cerosdotcom/oscars-speeches                             Oscars speeches since 1939                          523KB  2018-03-02 16:07:32            220  \n",
            "ardenthira/hollywood-black-list-20082017                Hollywood Black List, 2008-2017                     257KB  2018-05-15 15:30:54             69  \n",
            "Downloading academy-awards.zip to ./datasets/academy-awards\n",
            "  0% 0.00/185k [00:00<?, ?B/s]\n",
            "100% 185k/185k [00:00<00:00, 69.4MB/s]\n",
            "Archive:  ./datasets/academy-awards/academy-awards.zip\n",
            "  inflating: ./datasets/academy-awards/database.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiHOv7i5TEtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! rm -rf /content/datasets/academy-awards/academy-awards.pony.db"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jm9HeghYCzD",
        "colab_type": "code",
        "outputId": "8690c6a7-f1fb-475d-ab85-3159d14badd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from pony.orm import *\n",
        "import pandas\n",
        "\n",
        "# Creating a new database\n",
        "db_aa = Database()\n",
        "db_aa.bind(provider='sqlite', filename='/content/datasets/academy-awards/academy-awards.pony.db', create_db=True)\n",
        "\n",
        "class AcademyAward(db_aa.Entity):\n",
        "    Year = Required(str) \n",
        "    Ceremony = Required(int)\n",
        "    Award = Required(str)\n",
        "    Winner = Optional(float)\n",
        "    Name = Required(str)\n",
        "    Film = Optional(str)\n",
        "\n",
        "show(AcademyAward)\n",
        "#set_sql_debug(True)\n",
        "db_aa.generate_mapping(create_tables=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class AcademyAward(Entity):\n",
            "    id = PrimaryKey(int, auto=True)\n",
            "    Year = Required(str)\n",
            "    Ceremony = Required(int)\n",
            "    Award = Required(str)\n",
            "    Winner = Optional(float)\n",
            "    Name = Required(str)\n",
            "    Film = Optional(str, default='')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9CPXi03QguT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "\n",
        "df_aa = pandas.read_csv(\"./datasets/academy-awards/database.csv\")\n",
        "df_aa['Winner'].fillna(0.0, inplace=True)\n",
        "\n",
        "for idx, row in df_aa.iterrows():\n",
        "    AcademyAward(\n",
        "            Year=row['Year'],\n",
        "            Ceremony=row['Ceremony'],\n",
        "            Award=row['Award'],\n",
        "            Winner=row['Winner'],\n",
        "            Name=row['Name'],\n",
        "            Film=(row['Film'] if not type(row['Film']) is float else \"\")\n",
        "    )\n",
        "commit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O29mBKifUjRP",
        "colab_type": "code",
        "outputId": "58f4629b-2ba9-4935-88e2-2bc22165c9ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "    SELECT \"a\".\"Film\", COUNT(DISTINCT \"a\".\"id\")\n",
        "    FROM \"AcademyAward\" \"a\"\n",
        "    WHERE \"a\".\"Award\" = 'Directing'\n",
        "    GROUP BY \"a\".\"Film\"\n",
        "    ORDER BY COUNT(DISTINCT \"a\".\"id\") DESC\n",
        "    LIMIT 1\n",
        "\"\"\"\n",
        "# The query suppose to use GRPOUP BY \"a\".\"Name\" since we would like to create groups of the same person\n",
        "# But there is an error in the database, in some rows the data in 'Film' and 'Name' are replaced\n",
        "# hence in order to get the correct answer the query need to use \"a\".\"Film\".\n",
        "most_award = select((a.Film, count(a)) for a in AcademyAward).where(lambda a: a.Award == 'Directing')\n",
        "most_award_desc = most_award.order_by(lambda x,y: desc(y)).limit(1)\n",
        "list(most_award_desc)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('William Wyler', 12)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va320K09YCzE",
        "colab_type": "text"
      },
      "source": [
        "**Question 3:** Which top-10 movies received the highest number of Oscar nominees? (10pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9gVwnHVYCzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF15wiyqYCzH",
        "colab_type": "text"
      },
      "source": [
        "**Question 4:** Write a function that receives an actor's name and returns the actor’s number of Oscar nominees. Use the function to calculate the number of times Leonardo DiCaprio was a nominee (10pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZdwQJCWYCzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW1N-PBiYCzJ",
        "colab_type": "text"
      },
      "source": [
        "## 5. Select a Dataset (15pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me79ek_mYCzJ",
        "colab_type": "text"
      },
      "source": [
        "**Open Question:** Select an interesting dataset and use SQL to discover something interesting (15pt). **Bonus:** Use BigQuery (2pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXIIUhgccGWw",
        "colab_type": "code",
        "outputId": "70e0ac90-d0b5-415d-abb7-dee77fda1d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# download and unzip dataset\n",
        "!kaggle datasets download shivamb/netflix-shows -p ./datasets/netflix-shows/\n",
        "!unzip ./datasets/netflix-shows/netflix-shows.zip -d ./datasets/netflix-shows/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "netflix-shows.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  ./datasets/netflix-shows/netflix-shows.zip\n",
            "replace ./datasets/netflix-shows/netflix_titles.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: מ\n",
            "error:  invalid response [מ]\n",
            "replace ./datasets/netflix-shows/netflix_titles.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: מ\n",
            "error:  invalid response [מ]\n",
            "replace ./datasets/netflix-shows/netflix_titles.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XdInWyykCQ68",
        "colab": {}
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "\n",
        "TEXT_PATH_NS = './datasets/netflix-shows/netflix_titles.csv'\n",
        "DB_PATH_NS = './datasets/netflix-shows/netflix-shows.sqlite'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9b7b1e28-ed09-4211-da6f-dc2414056173",
        "id": "aWqfhPviCQ7D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas\n",
        "\n",
        "conn_ns = sqlite3.connect(DB_PATH_NS) # connecting to the database\n",
        "c_ns = conn_ns.cursor() # creating a cursor object\n",
        "\n",
        "c_ns.execute(\n",
        "        '''CREATE TABLE IF NOT EXISTS NetflixShow\n",
        "             ([show_id] integer,\n",
        "              [type] text,\n",
        "              [title] text,\n",
        "              [director] text,\n",
        "              [cast] text,\n",
        "              [country] text,\n",
        "              [date_added] text,\n",
        "              [release_year] interger,\n",
        "              [rating] text,\n",
        "              [duration] text,\n",
        "              [listed_in] text,\n",
        "              [description] text\n",
        "              )\n",
        "        '''\n",
        ")\n",
        "\n",
        "df_ns = pandas.read_csv(\"./datasets/netflix-shows/netflix-shows.zip\")\n",
        "#load data into convinient format\n",
        "shows = [tuple(dict(row).values()) for idx, row in df_ns.iterrows()]\n",
        "\n",
        "# insert data to db\n",
        "c_ns.executemany(\n",
        "    '''INSERT INTO NetflixShow(show_id, type, title, director, cast, country,\n",
        "                               date_added, release_year, rating, duration, listed_in,\n",
        "                               description) values (?,?,?,?,?,?,?,?,?,?,?,?)\n",
        "    ''', shows\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sqlite3.Cursor at 0x7f87c8ed2e30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZiEhrE_GAhP",
        "colab_type": "code",
        "outputId": "9a4f907b-7230-403f-a086-e32ccf9e3cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# The database contains the different contents (movies, series) added to netflix (2010-2019).\n",
        "# In the db we can find the date of releasing the content, and when the content was added\n",
        "# to netflix.\n",
        "# My guess is that we will see massive growth in the ammount of content added each year due to \n",
        "# the consuming colture and the 'netflix' revolution we all know.\n",
        "c_ns.execute(\n",
        "    ''' SELECT SUBSTR(date_added, -4), COUNT(*)\n",
        "        FROM NetflixShow\n",
        "        GROUP BY SUBSTR(date_added, -4)\n",
        "        ORDER BY 1 ASC\n",
        "    '''\n",
        ").fetchall()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(None, 11),\n",
              " ('2008', 2),\n",
              " ('2009', 2),\n",
              " ('2010', 1),\n",
              " ('2011', 13),\n",
              " ('2012', 7),\n",
              " ('2013', 12),\n",
              " ('2014', 25),\n",
              " ('2015', 90),\n",
              " ('2016', 456),\n",
              " ('2017', 1300),\n",
              " ('2018', 1782),\n",
              " ('2019', 2349),\n",
              " ('2020', 184)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}